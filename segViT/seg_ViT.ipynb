{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHAT IS ATM ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir/miniconda3/envs/mlptorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/emir/miniconda3/envs/mlptorch/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from mmseg.apis import init_segmentor, inference_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "from mmcv import Config\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pli\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import numpy as np\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from eddy_seg_vit import load_model, predict_random_img\n",
    "from dataset_parser import EddyDatasetREGISTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = \"/home/emir/Desktop/dev/myResearch/checkpoints/iter_150000.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/emir/Desktop/dev/myResearch/checkpoints/iter_150000.pth\n"
     ]
    }
   ],
   "source": [
    "classes = EddyDatasetREGISTER.CLASSES\n",
    "palette = EddyDatasetREGISTER.PALETTE\n",
    "seg_Vit_L_cfg = \"./configs/SegViT_L_EddyData.py\"\n",
    "model = load_model(config=seg_Vit_L_cfg, checkpoint=cp, device=device, CLASSES=classes, PALETTE=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (backbone): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (adap_padding): AdaptivePadding()\n",
       "      (projection): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (6): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (7): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (8): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (9): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (10): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (11): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (12): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (13): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (14): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (15): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (16): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (17): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (18): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (19): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (20): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (21): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (22): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (23): TransformerEncoderLayer(\n",
       "        (ln1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (activate): GELU(approximate='none')\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): DropPath()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): ATMHead(\n",
       "    input_transform=None, ignore_index=255, align_corners=False\n",
       "    (loss_decode): ATMLoss(\n",
       "      (criterion): SetCriterion()\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (input_proj_1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (proj_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder_1): TPN_Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_proj_2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (proj_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder_2): TPN_Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_proj_3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (proj_norm_3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder_3): TPN_Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): TPN_DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (multihead_attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (q): Embedding(1, 512)\n",
       "    (class_embed): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/\"\n",
    "test_label = \"/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_label_aug/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Dir /home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_label_aug/7_5_1_201_aug.png\n",
      "img dir /home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat\n",
      "len imgs = 91\n",
      "len of imgs 1\n",
      "pad_shape is not found in results\n",
      "scale_factor is not found in results\n",
      "img_norm_cfg is not found in results\n",
      "pad_shape is not found in results\n",
      "scale_factor is not found in results\n",
      "img_norm_cfg is not found in results\n",
      "pad_shape is not found in results\n",
      "scale_factor is not found in results\n",
      "img_norm_cfg is not found in results\n",
      "pad_shape is not found in results\n",
      "scale_factor is not found in results\n",
      "img_norm_cfg is not found in results\n",
      "pad_shape is not found in results\n",
      "scale_factor is not found in results\n",
      "img_norm_cfg is not found in results\n",
      "pad_shape is not found in results\n",
      "scale_factor is not found in results\n",
      "img_norm_cfg is not found in results\n",
      "aug_Data_dict img shape 6\n",
      "type of model <class 'mmseg.models.segmentors.encoder_decoder.EncoderDecoder'>\n",
      "img_metas [[{'filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_shape': (256, 256, 3), 'img_shape': (256, 256, 3), 'flip': False, 'flip_direction': 'horizontal'}], [{'filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_shape': (256, 256, 3), 'img_shape': (256, 256, 3), 'flip': False, 'flip_direction': 'horizontal'}], [{'filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_shape': (256, 256, 3), 'img_shape': (256, 256, 3), 'flip': False, 'flip_direction': 'horizontal'}], [{'filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_shape': (256, 256, 3), 'img_shape': (256, 256, 3), 'flip': False, 'flip_direction': 'horizontal'}], [{'filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_shape': (256, 256, 3), 'img_shape': (256, 256, 3), 'flip': False, 'flip_direction': 'horizontal'}], [{'filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_filename': '/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_data_aug_mat/7_5_1_201_aug.mat', 'ori_shape': (256, 256, 3), 'img_shape': (256, 256, 3), 'flip': False, 'flip_direction': 'horizontal'}]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pad_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/emir/Desktop/dev/myResearch/src/ViT_Segmentation/segViT/seg_ViT.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmlgpu/home/emir/Desktop/dev/myResearch/src/ViT_Segmentation/segViT/seg_ViT.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m predict_random_img(model\u001b[39m=\u001b[39;49mmodel, data_dir\u001b[39m=\u001b[39;49mtest_dir, label_dir\u001b[39m=\u001b[39;49mtest_label)\n",
      "File \u001b[0;32m~/Desktop/dev/myResearch/src/ViT_Segmentation/segViT/eddy_seg_vit.py:205\u001b[0m, in \u001b[0;36mpredict_random_img\u001b[0;34m(model, data_dir, label_dir)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLabel Dir \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg dir \u001b[39m\u001b[39m{\u001b[39;00mimg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m result \u001b[39m=\u001b[39m inference_segmentor(model\u001b[39m=\u001b[39;49mmodel, imgs\u001b[39m=\u001b[39;49mimg)\n\u001b[1;32m    206\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[1;32m    207\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/dev/myResearch/src/mmsegmentation/mmseg/apis/inference.py:127\u001b[0m, in \u001b[0;36minference_segmentor\u001b[0;34m(model, imgs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    125\u001b[0m     \u001b[39m# print(f\"print data in inference {data}\")\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype of model \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(model)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m     result \u001b[39m=\u001b[39m model(return_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, rescale\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    128\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresult shape \u001b[39m\u001b[39m{\u001b[39;00mresult[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/mlptorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mlptorch/lib/python3.10/site-packages/mmcv/runner/fp16_utils.py:119\u001b[0m, in \u001b[0;36mauto_fp16.<locals>.auto_fp16_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m@auto_fp16 can only be used to decorate the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    117\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmethod of those classes \u001b[39m\u001b[39m{\u001b[39;00msupported_types\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mfp16_enabled\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfp16_enabled):\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m old_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    121\u001b[0m \u001b[39m# get the arg spec of the decorated method\u001b[39;00m\n\u001b[1;32m    122\u001b[0m args_info \u001b[39m=\u001b[39m getfullargspec(old_func)\n",
      "File \u001b[0;32m~/Desktop/dev/myResearch/src/mmsegmentation/mmseg/models/segmentors/base.py:115\u001b[0m, in \u001b[0;36mBaseSegmentor.forward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_train(img, img_metas, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[39m# print(\"iam in 1\")\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_test(img, img_metas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/dev/myResearch/src/mmsegmentation/mmseg/models/segmentors/base.py:90\u001b[0m, in \u001b[0;36mBaseSegmentor.forward_test\u001b[0;34m(self, imgs, img_metas, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     img_shapes \u001b[39m=\u001b[39m [_[\u001b[39m'\u001b[39m\u001b[39mimg_shape\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m img_meta]\n\u001b[1;32m     89\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(shape \u001b[39m==\u001b[39m img_shapes[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m img_shapes)\n\u001b[0;32m---> 90\u001b[0m     pad_shapes \u001b[39m=\u001b[39m [_[\u001b[39m'\u001b[39m\u001b[39mpad_shape\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m img_meta]\n\u001b[1;32m     91\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(shape \u001b[39m==\u001b[39m pad_shapes[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m pad_shapes)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m num_augs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[39m# print(\"iam in 1\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/dev/myResearch/src/mmsegmentation/mmseg/models/segmentors/base.py:90\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     88\u001b[0m     img_shapes \u001b[39m=\u001b[39m [_[\u001b[39m'\u001b[39m\u001b[39mimg_shape\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m img_meta]\n\u001b[1;32m     89\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(shape \u001b[39m==\u001b[39m img_shapes[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m img_shapes)\n\u001b[0;32m---> 90\u001b[0m     pad_shapes \u001b[39m=\u001b[39m [_[\u001b[39m'\u001b[39;49m\u001b[39mpad_shape\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m img_meta]\n\u001b[1;32m     91\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(shape \u001b[39m==\u001b[39m pad_shapes[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m pad_shapes)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m num_augs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[39m# print(\"iam in 1\")\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pad_shape'"
     ]
    }
   ],
   "source": [
    "predict_random_img(model=model, data_dir=test_dir, label_dir=test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir/miniconda3/envs/mlptorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0], device='cuda:0'), tensor([1], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[torch.tensor([1]).to('cuda'), torch.tensor([0])]]\n",
    "batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices)])\n",
    "src_idx = torch.cat([src for (src, _) in indices])\n",
    "batch_idx, src_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0]), tensor([0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx = torch.cat([torch.full_like(tgt, i) for i, (_, tgt) in enumerate(indices)])\n",
    "tgt_idx = torch.cat([tgt for (_, tgt) in indices])\n",
    "batch_idx, tgt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = torch.tensor([0]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir/miniconda3/envs/mlptorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "cls =0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = []\n",
    "cls =0\n",
    "example = \"/home/emir/Desktop/dev/myResearch/dataset/dataset_eddy/valid_label_aug/7_2_51_51_aug.png\"\n",
    "img = mpimg.imread(example)\n",
    "img = torch.tensor(img)\n",
    "print(img.shape)\n",
    "masks.append(img == cls)\n",
    "masks.append(img == 255)\n",
    "masks = torch.stack(masks, dim=0)\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 256])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6351ae7a8af7abb5b6e92ecd3cb8e4a903e7aa1ff53853f1ec32897af5c10b9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
